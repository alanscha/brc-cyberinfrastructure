{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Drive Cleanup (incomplete)\n",
    "### Nicolas Chan, 10/17/2017\n",
    "Looks through Google Drive results folder and finds consecutive ranges of completed results. Combines these results into one folder of a larger range. This also identifies ranges that have not been completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "results_folder_id = '0B1297pLT9WXLV29iNmlWcTlvakk'\n",
    "temp_folder = '/global/scratch/nicolaschan/tmp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credential_path: <oauth2client.client.OAuth2Credentials object at 0x2af5b032e630>\n"
     ]
    }
   ],
   "source": [
    "# Copied from AdamAndersonFindSumerianWorkflow\n",
    "\n",
    "#Make Directories if they do not exist\n",
    "import os\n",
    "import sys\n",
    "import errno\n",
    "\n",
    "def dir_create(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exception:\n",
    "        if exception.errno != errno.EEXIST:\n",
    "            raise\n",
    "        else:\n",
    "            print('Folder at: ' + path + ' already exists. Skipping...')\n",
    "\n",
    "# bDrive Authorization\n",
    "import os\n",
    "import codecs\n",
    "import httplib2\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "from apiclient import discovery, errors\n",
    "from oauth2client import client\n",
    "from oauth2client import tools\n",
    "from oauth2client.file import Storage\n",
    "\n",
    "SCOPES = 'https://www.googleapis.com/auth/drive'\n",
    "CLIENT_SECRET_FILE = 'client_secret.json'\n",
    "APPLICATION_NAME = 'gDriveConnect'\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(parents=[tools.argparser])\n",
    "parser.add_argument('-f', help=argparse.SUPPRESS)\n",
    "\n",
    "flags = parser.parse_known_args()[0]\n",
    "flags.noauth_local_webserver = True\n",
    "\n",
    "def get_credentials():\n",
    "    \n",
    "    home_dir = os.path.expanduser('~')\n",
    "    credential_dir = os.path.join(home_dir, '.credentials')\n",
    "    if not os.path.exists(credential_dir):\n",
    "        os.makedirs(credential_dir)\n",
    "    credential_path = os.path.join(credential_dir, 'gDriveConnect.json')\n",
    "    \n",
    "    store = Storage(credential_path)    \n",
    "    credentials = store.get()\n",
    "    \n",
    "    if not credentials or credentials.invalid:\n",
    "        flow = client.flow_from_clientsecrets(CLIENT_SECRET_FILE, SCOPES)\n",
    "        flow.user_agent = APPLICATION_NAME\n",
    "        if flags:\n",
    "            credentials = tools.run_flow(flow, store, flags)\n",
    "        else: # Needed only for compatibility with Python 2.6\n",
    "            credentials = tools.run(flow, store)\n",
    "        print('Storing credentials to ' + credential_path)\n",
    "        \n",
    "    return credentials\n",
    "\n",
    "credentials = get_credentials()\n",
    "print('credential_path:', credentials)\n",
    "http = credentials.authorize(httplib2.Http())\n",
    "service = discovery.build('drive', 'v3', http=http)\n",
    "\n",
    "def get_drive_contents(folder_id):\n",
    "    contents = []\n",
    "    query=\"'\" + folder_id + \"' in parents and trashed=false\"\n",
    "    \n",
    "    # This implementation is copied from below (commented out)\n",
    "    page_token = None\n",
    "    while True:\n",
    "        response = service.files().list(q=query,\n",
    "                                             spaces='drive',\n",
    "                                             fields='nextPageToken, files(id, name)',\n",
    "                                             pageToken=page_token).execute()\n",
    "        for file in response.get('files', []):\n",
    "            # Process change\n",
    "            # print('Found file: %s (%s)' % (file.get('name'), file.get('id')) )\n",
    "            tup = (file.get('name'), file.get('id'))\n",
    "            contents.append(tup)\n",
    "        page_token = response.get('nextPageToken', None)\n",
    "        if page_token is None:\n",
    "            break;\n",
    "    return contents\n",
    "\n",
    "import io\n",
    "def download_file(google_id, destination):\n",
    "    \"\"\"Downloads a file from Google Drive\"\"\"\n",
    "    \n",
    "    request = service.files().get_media(fileId=google_id)\n",
    "    fh = io.FileIO(destination, mode='wb')\n",
    "    downloader = MediaIoBaseDownload(fh, request, chunksize=1024*1024)\n",
    "    \n",
    "    done = False\n",
    "    while done is False:\n",
    "        status, done = downloader.next_chunk()\n",
    "        \n",
    "    \n",
    "# Added by Nicolas Chan, 10/12/2017\n",
    "def create_drive_folder(name, parent=None):\n",
    "    \"Create a new Google Drive folder, nested under parent\"\n",
    "    \n",
    "    body = { 'name': name, 'mimeType': 'application/vnd.google-apps.folder' }\n",
    "    if parent:\n",
    "        body['parents'] = [parent]\n",
    "    return service.files().create(body = body).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def folder_finished(contents):\n",
    "    \"\"\"Returns Google IDs of bighitlist.txt and smallhitlist.txt, if they exist\"\"\"\n",
    "    bighitlist = None\n",
    "    smallhitlist = None\n",
    "    for file in contents:\n",
    "        if file[0] == 'bighitlist.txt':\n",
    "            bighitlist = file[1]\n",
    "        if file[0] == 'smallhitlist.txt':\n",
    "            smallhitlist = file[1]\n",
    "        if bighitlist and smallhitlist:\n",
    "            return bighitlist, smallhitlist # short circuits for efficiency\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results_0-1 : True\n",
      "Results_2-3 : False\n",
      "Results_4-4 : True\n",
      "Results_5-5 : False\n",
      "Results_6-8 : True\n",
      "Results_9-11 : False\n",
      "Results_12-14 : False\n",
      "Results_15-17 : True\n",
      "Results_18-22 : False\n",
      "Results_23-27 : False\n",
      "Results_28-32 : False\n",
      "Results_33-33 : True\n",
      "Results_34-34 : True\n",
      "Results_35-44 : True\n",
      "Results_45-45 : True\n",
      "Results_46-55 : True\n",
      "Results_56-60 : True\n",
      "Results_61-65 : True\n",
      "Results_66-70 : True\n",
      "Results_71-75 : True\n",
      "Results_76-80 : True\n",
      "Results_81-85 : True\n",
      "Results_86-90 : False\n",
      "Results_91-95 : True\n",
      "Results_96-100 : True\n",
      "Results_101-105 : True\n"
     ]
    }
   ],
   "source": [
    "results_folders = get_drive_contents(results_folder_id)\n",
    "results_folders = sorted(results_folders, key=lambda folder: int(folder[0].split('_')[1].split('-')[0]))\n",
    "# print(results_folders)\n",
    "\n",
    "consecutive_completed_ranges = [[]]\n",
    "for results_folder in results_folders:\n",
    "    contents = get_drive_contents(results_folder[1])\n",
    "    bighitlist, smallhitlist = folder_finished(contents)\n",
    "    \n",
    "    if bighitlist and smallhitlist:\n",
    "        consecutive_completed_ranges[-1].append({\n",
    "                'results_folder': results_folder,\n",
    "                'smallhits': smallhitlist,\n",
    "                'bighits': bighitlist\n",
    "            })\n",
    "    elif len(consecutive_completed_ranges[-1]) > 0:\n",
    "        consecutive_completed_ranges.append([])\n",
    "    \n",
    "    print(results_folder[0], ':', bool(bighitlist and smallhitlist))\n",
    "\n",
    "# Remove ranges of length 1\n",
    "consecutive_completed_ranges = [ r for r in consecutive_completed_ranges if len(r) > 1 ]\n",
    "\n",
    "print(consecutive_completed_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder at: /global/scratch/nicolaschan/tmp/Results_33-33/ already exists. Skipping...\n",
      "Folder at: /global/scratch/nicolaschan/tmp/Results_34-34/ already exists. Skipping...\n"
     ]
    },
    {
     "ename": "HttpError",
     "evalue": "<HttpError 416 when requesting https://www.googleapis.com/drive/v3/files/0B1297pLT9WXLNTZWaGNUSk90NjA?alt=media returned \"Request range not satisfiable\">",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f434faab8eb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mbighit_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'bighitlist.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'smallhits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmallhit_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bighits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbighit_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0msmallhits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmallhit_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mbighits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbighit_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-20994eb4c331>\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(google_id, destination)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/software/sl-6.x86_64/modules/langs/python/3.5.1/lib/python3.5/site-packages/oauth2client/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/software/sl-6.x86_64/modules/langs/python/3.5.1/lib/python3.5/site-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mnext_chunk\u001b[0;34m(self, num_retries)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mMediaDownloadProgress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHttpError\u001b[0m: <HttpError 416 when requesting https://www.googleapis.com/drive/v3/files/0B1297pLT9WXLNTZWaGNUSk90NjA?alt=media returned \"Request range not satisfiable\">"
     ]
    }
   ],
   "source": [
    "# concatenate_files based on https://stackoverflow.com/a/13613375/8706910\n",
    "def concatenate_files(files, output_file):\n",
    "    with open(output_file, 'w') as output:\n",
    "        for file in files:\n",
    "            print(file)\n",
    "            with open(file) as input_file:\n",
    "                for line in input_file:\n",
    "                    output.write(line)\n",
    "                \n",
    "\n",
    "def results_folder_to_range(folder_name):\n",
    "    start, end = folder_name.split('_')[1].split('-')\n",
    "    return int(start), int(end)\n",
    "\n",
    "new_ranges = []\n",
    "for ranges in consecutive_completed_ranges:\n",
    "    smallhits = []\n",
    "    bighits = []\n",
    "    start_index = None\n",
    "    end_index = None\n",
    "    for folder in ranges:\n",
    "        folder_name = folder['results_folder'][0]\n",
    "        start, end = results_folder_to_range(folder_name)\n",
    "        \n",
    "        start_index = start if start_index == None  else min(start, start_index)\n",
    "        end_index = end if end_index == None else max(end, end_index)\n",
    "        \n",
    "        path = temp_folder + folder_name + '/'\n",
    "        dir_create(path)\n",
    "        smallhit_file = path + 'smallhitlist.txt'\n",
    "        bighit_file = path + 'bighitlist.txt'\n",
    "        download_file(folder['smallhits'], smallhit_file)\n",
    "        download_file(folder['bighits'], bighit_file)\n",
    "        smallhits.append(smallhit_file)\n",
    "        bighits.append(bighit_file)\n",
    "        \n",
    "    combined_folder = temp_folder + 'Combined_'  + str(start_index) + '-' + str(end_index)\n",
    "    dir_create(combined_folder)\n",
    "    \n",
    "    concatenate_files(smallhits, combined_folder + '/smallhitlist.txt')\n",
    "    concatenate_files(bighits, combined_folder + '/bighitlist.txt')\n",
    "    print(smallhits, bighits, start_index, end_index)\n",
    "    \n",
    "    # print('range', start_index, end_index)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
